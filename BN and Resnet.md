## 1. 批量归一化BN
通常做法是在神经网络输入，hidden layer输出与激活函数之间设置批量归一化，使整个神经网络在各层的中间输出的数值更稳定。同时也有助于解决梯度爆炸和梯度消失问题。
## 2. Resnet
解决的问题：深度学习的问题：深度CNN网络达到一定深度后再一味地增加层数并不能带来进一步地分类性能提高，反而会招致网络收敛变得更慢，准确率也变得更差。</br>
增加shortcut connection之后，保持一路恒等映射，那么即使之后堆上去的网络什么也不做，模型的效果也不会变差。
## 3. Densnet
主要构建模块：
稠密块（dense block）： 定义了输入和输出是如何连结的。
过渡层（transition layer）：用来控制通道数，使之不过大;----1*1卷积层：来减小通道数,步幅为2的平均池化层：减半高和宽
