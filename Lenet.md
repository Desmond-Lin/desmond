## 1. Lenet
基本结构是1.5*5的卷积层 2.Sigmoid层 3. average pooling层,最后再加上一个全连接层。
## 2. AlexNet
和lenet对比，sigmoid激活函数改成了更加简单的ReLU激活函数，用Dropout来控制全连接层的模型复杂度。
## 3. VGG
通过重复使⽤简单的基础块来构建深度模型。
## 4.Nin
NiN重复使⽤由卷积层和代替全连接层的1×1卷积层构成的NiN块来构建深层⽹络。
NiN去除了容易造成过拟合的全连接输出层，而是将其替换成输出通道数等于标签类别数 的NiN块和全局平均池化层。
使用1×1卷积核作用：
1.放缩通道数(降维）：通过控制卷积核的数量达到通道数的放缩。
2.增加非线性。1×1卷积核的卷积过程相当于全连接层的计算过程，并且还加入了非线性激活函数，从而可以增加网络的非线性。
3.计算参数少
## 5. GoogLeNet
由Inception基础块组成。
Inception块相当于⼀个有4条线路的⼦⽹络。它通过不同窗口形状的卷积层和最⼤池化层来并⾏抽取信息，并使⽤1×1卷积层减少通道数从而降低模型复杂度。
可以⾃定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。


